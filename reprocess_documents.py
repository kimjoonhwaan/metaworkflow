#!/usr/bin/env python3
"""
ê¸°ì¡´ ë¬¸ì„œë¥¼ ìƒˆ RAG ì„¤ì •ìœ¼ë¡œ ìž¬ì²˜ë¦¬í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
import sys
import os
from pathlib import Path

# ê²½ë¡œ ì„¤ì •
sys.path.insert(0, os.path.dirname(__file__))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import asyncio
from src.database.session import get_session
from src.database.models import Document, DocumentChunk
from src.services.rag_service import RAGService
from src.utils.config import get_settings
from src.utils.logger import get_logger

logger = get_logger("reprocess_documents")

async def cleanup_chroma_db():
    """ChromaDB ë””ë ‰í† ë¦¬ ì •ë¦¬"""
    chroma_path = Path("./data/chroma_db")
    
    if chroma_path.exists():
        print(f"\nðŸ—‘ï¸  ChromaDB ì •ë¦¬ ì¤‘: {chroma_path}")
        try:
            # ë°±ì—… ìƒì„±
            backup_path = Path("./data/chroma_db.backup")
            if backup_path.exists():
                shutil.rmtree(backup_path)
            shutil.move(str(chroma_path), str(backup_path))
            print(f"   âœ… ë°±ì—… ìƒì„±: {backup_path}")
        except Exception as e:
            logger.error(f"ChromaDB ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return False
    
    return True

async def clear_document_chunks():
    """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê¸°ì¡´ ì²­í¬ ì‚­ì œ"""
    print(f"\nðŸ—‘ï¸  ê¸°ì¡´ ì²­í¬ ì‚­ì œ ì¤‘...")
    
    with get_session() as session:
        try:
            chunk_count = session.query(DocumentChunk).count()
            print(f"   ì‚­ì œí•  ì²­í¬: {chunk_count}ê°œ")
            
            session.query(DocumentChunk).delete()
            session.commit()
            
            print(f"   âœ… ëª¨ë“  ì²­í¬ ì‚­ì œë¨")
            return True
        except Exception as e:
            logger.error(f"ì²­í¬ ì‚­ì œ ì‹¤íŒ¨: {e}")
            session.rollback()
            return False

async def reprocess_documents():
    """ëª¨ë“  ë¬¸ì„œë¥¼ ìƒˆë¡œìš´ ì„¤ì •ìœ¼ë¡œ ìž¬ìž„ë² ë”©"""
    print(f"\nðŸ“š ë¬¸ì„œ ìž¬ìž„ë² ë”© ì‹œìž‘...")
    print(f"   ì„¤ì •: chunk_size=1500, overlap=300")
    print("=" * 80)
    
    rag_service = RAGService()
    
    with get_session() as session:
        # ìž„ë² ë”©í•  ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ
        documents = session.query(Document).filter(
            Document.is_processed == True
        ).all()
        
        print(f"\nìž¬ìž„ë² ë”©í•  ë¬¸ì„œ: {len(documents)}ê°œ")
        
        if not documents:
            print("   âš ï¸  ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
            return True
        
        success_count = 0
        failed_count = 0
        
        for idx, doc in enumerate(documents, 1):
            doc_name = doc.title[:40] + "..." if len(doc.title) > 40 else doc.title
            
            try:
                print(f"\n[{idx}/{len(documents)}] ðŸ“„ {doc_name}")
                print(f"   ID: {doc.id}")
                
                # 1ë‹¨ê³„: ê¸°ì¡´ ì²­í¬ ì‚­ì œ
                session.query(DocumentChunk).filter(
                    DocumentChunk.document_id == doc.id
                ).delete()
                session.commit()
                print(f"   âœ… ê¸°ì¡´ ì²­í¬ ì‚­ì œë¨")
                
                # 2ë‹¨ê³„: ìƒˆë¡œìš´ ì„¤ì •ìœ¼ë¡œ ìž¬ìž„ë² ë”©
                # add_documentëŠ” ë‚´ë¶€ì ìœ¼ë¡œ chunk_textë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ
                # ìƒˆë¡œìš´ chunk_size(1500)ì™€ overlap(300)ì´ ìžë™ ì ìš©ë¨
                print(f"   â³ ìž¬ìž„ë² ë”© ì¤‘...")
                
                # ë¬¸ì„œì˜ ì²­í¬ë¥¼ ìƒˆë¡œìš´ ì„¤ì •ìœ¼ë¡œ ë‹¤ì‹œ ìƒì„±
                chunks = rag_service.chunk_text(
                    doc.content,
                    chunk_size=1500,  # ìƒˆë¡œìš´ í¬ê¸°
                    overlap=300        # ìƒˆë¡œìš´ ì˜¤ë²„ëž©
                )
                
                print(f"   âœ… ì²­í¬ ìƒì„±: {len(chunks)}ê°œ (ì´ì „ë³´ë‹¤ ì ì„ ê²ƒìž„)")
                
                # 3ë‹¨ê³„: ìž„ë² ë”© ìƒì„± ë° ì €ìž¥
                collection = rag_service._get_or_create_collection(doc.knowledge_base.category)
                
                embedding_count = 0
                for i, chunk_content in enumerate(chunks):
                    # ìž„ë² ë”© ìƒì„±
                    embedding = await rag_service.create_embedding(chunk_content)
                    
                    # ChromaDBì— ì €ìž¥
                    chunk_id = f"{doc.id}_chunk_{i}"
                    collection.add(
                        ids=[chunk_id],
                        embeddings=[embedding],
                        documents=[chunk_content],
                        metadatas=[{
                            "document_id": doc.id,
                            "chunk_index": i,
                            "title": doc.title,
                            "content_type": doc.content_type.value,
                            "category": doc.knowledge_base.category.value,
                            "has_previous": i > 0,
                            "has_next": i < len(chunks) - 1
                        }]
                    )
                    
                    # DocumentChunk ë ˆì½”ë“œ ìƒì„±
                    chunk = DocumentChunk(
                        document_id=doc.id,
                        chunk_index=i,
                        content=chunk_content,
                        embedding_id=chunk_id,
                        start_char=i * (1500 - 300),
                        end_char=min((i + 1) * 1500, len(doc.content)),
                        token_count=len(rag_service.tokenizer.encode(chunk_content))
                    )
                    session.add(chunk)
                    embedding_count += 1
                
                session.commit()
                print(f"   âœ… ìž„ë² ë”© ì €ìž¥: {embedding_count}ê°œ")
                
                # 4ë‹¨ê³„: ë¬¸ì„œ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
                doc.vector_count = len(chunks)
                doc.is_processed = True
                session.commit()
                
                success_count += 1
                print(f"   âœ… ì™„ë£Œ!")
                
                # ì§„í–‰ë¥  í‘œì‹œ
                if idx % 5 == 0:
                    print(f"\n   ðŸ“Š ì§„í–‰ë¥ : {idx}/{len(documents)} ({idx*100//len(documents)}%)")
                
            except Exception as e:
                failed_count += 1
                print(f"   âŒ ì˜¤ë¥˜: {str(e)[:100]}")
                logger.error(f"ìž¬ìž„ë² ë”© ì‹¤íŒ¨ {doc.id}: {e}", exc_info=True)
                session.rollback()
        
        print("\n" + "=" * 80)
        print(f"âœ… ìž¬ìž„ë² ë”© ì™„ë£Œ!")
        print(f"   ì„±ê³µ: {success_count}ê°œ")
        print(f"   ì‹¤íŒ¨: {failed_count}ê°œ")
        
        return failed_count == 0

async def main():
    print("=" * 80)
    print("ðŸ”„ ë¬¸ì„œ ìž¬ìž„ë² ë”© ì‹œìž‘")
    print("=" * 80)
    print("\nâš ï¸  ì£¼ì˜:")
    print("   - ëª¨ë“  ê¸°ì¡´ ì²­í¬ê°€ ì‚­ì œë˜ê³  ìƒˆë¡œ ìƒì„±ë©ë‹ˆë‹¤")
    print("   - ChromaDBê°€ ìž¬ìƒì„±ë©ë‹ˆë‹¤")
    print("   - ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤ (ë¬¸ì„œ ìˆ˜ì— ë”°ë¼ 5-30ë¶„)")
    print()
    
    # ìžë™ ì‹¤í–‰ (ëŒ€í™”í˜• ì œì™¸)
    print("ðŸš€ ì§„í–‰ ì¤‘...\n")
    
    # 1ë‹¨ê³„: ChromaDB ì •ë¦¬
    if not await cleanup_chroma_db():
        print("âŒ ChromaDB ì •ë¦¬ ì‹¤íŒ¨")
        return
    
    # 2ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ì²­í¬ ì‚­ì œ
    if not await clear_document_chunks():
        print("âŒ ì²­í¬ ì‚­ì œ ì‹¤íŒ¨")
        return
    
    # 3ë‹¨ê³„: ë¬¸ì„œ ìž¬ìž„ë² ë”©
    if await reprocess_documents():
        print("\nðŸŽ‰ ìž¬ìž„ë² ë”© ì„±ê³µ!")
        print("\në‹¤ìŒ ë‹¨ê³„:")
        print("   1. Streamlit ì•± ìž¬ì‹œìž‘")
        print("   2. ì›Œí¬í”Œë¡œìš° ìƒì„± íŽ˜ì´ì§€ì—ì„œ ìƒˆ ì¿¼ë¦¬ ì‹œë„")
        print("   3. RAG ì»¨í…ìŠ¤íŠ¸ê°€ ë” ë§Žì€ ì²­í¬ë¥¼ í¬í•¨í•˜ëŠ”ì§€ í™•ì¸")
    else:
        print("\nâš ï¸  ì¼ë¶€ ë¬¸ì„œ ìž¬ìž„ë² ë”© ì‹¤íŒ¨")
        print("   ë¡œê·¸ íŒŒì¼ í™•ì¸: ./logs/")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nâŒ ì‚¬ìš©ìžì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\n\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
