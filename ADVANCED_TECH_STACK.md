# ğŸš€ ê³ ê¸‰ ê¸°ìˆ  ìŠ¤íƒ: LLM, LangGraph, RAG, MCP, Memory

## 1ï¸âƒ£ **LLM (Large Language Model) Integration**

### **í˜„ì¬ ì„ íƒ: OpenAI GPT**

```
í”„ë¡œì íŠ¸ì—ì„œ LLMì˜ ì—­í• :
â”œâ”€ ì›Œí¬í”Œë¡œìš° ìƒì„± (ìì—°ì–´ â†’ ì›Œí¬í”Œë¡œìš° JSON)
â”œâ”€ ì½”ë“œ ìƒì„± (í”„ë¡¬í”„íŠ¸ â†’ Python ì½”ë“œ)
â”œâ”€ ì˜¤ë¥˜ í•´ê²° (ì˜¤ë¥˜ ë¡œê·¸ â†’ í•´ê²°ì±…)
â”œâ”€ ë¬¸ì„œ ìš”ì•½ (ê¸´ ë¬¸ì„œ â†’ ì§§ì€ ìš”ì•½)
â””â”€ ì˜ë„ ë¶„ì„ (ì‚¬ìš©ì ì¿¼ë¦¬ â†’ ì›Œí¬í”Œë¡œìš° ì˜ë„)
```

#### **ì‚¬ìš© ì¤‘ì¸ LLM ëª¨ë¸ë“¤**

```python
from openai import AsyncOpenAI

class LLMManager:
    def __init__(self):
        self.client = AsyncOpenAI(api_key=OPENAI_API_KEY)
    
    # 1. ì›Œí¬í”Œë¡œìš° ìƒì„±
    async def generate_workflow(self, user_query: str):
        """ìì—°ì–´ â†’ ì›Œí¬í”Œë¡œìš° JSON"""
        response = await self.client.chat.completions.create(
            model="gpt-4-turbo",          # â­ ìµœê³  ì„±ëŠ¥
            messages=[
                {"role": "system", "content": WORKFLOW_GENERATION_PROMPT},
                {"role": "user", "content": user_query}
            ],
            temperature=0.7,               # ì°½ì˜ì„±: 0.7
            max_tokens=4096
        )
        return response.choices[0].message.content
    
    # 2. ì½”ë“œ ìƒì„±
    async def generate_code(self, task: str):
        """ì‘ì—… â†’ Python ì½”ë“œ"""
        response = await self.client.chat.completions.create(
            model="gpt-4",                 # ì½”ë“œ ìƒì„±ì€ gpt-4
            messages=[...],
            temperature=0.3                # ì •í™•ì„±: 0.3
        )
        return response.choices[0].message.content
    
    # 3. ì„ë² ë”© ìƒì„± (RAGìš©)
    async def generate_embedding(self, text: str):
        """í…ìŠ¤íŠ¸ â†’ ë²¡í„° (384ì°¨ì›)"""
        response = await self.client.embeddings.create(
            model="text-embedding-3-small",  # â­ RAGìš©
            input=text,
            dimensions=384
        )
        return response.data[0].embedding
```

#### **ëª¨ë¸ë³„ ì„ íƒ ê¸°ì¤€**

| ëª¨ë¸ | ìš©ë„ | ì„±ëŠ¥ | ì†ë„ | ë¹„ìš© | ì„ íƒ |
|------|------|------|------|------|------|
| **GPT-4 Turbo** | ë³µì¡í•œ ì‘ì—… | â­â­â­â­â­ | â­â­â­ | ë¹„ìŒˆ | âœ… ì›Œí¬í”Œë¡œìš° ìƒì„± |
| **GPT-4** | ì½”ë“œ ìƒì„± | â­â­â­â­â­ | â­â­ | ë¹„ìŒˆ | âœ… ì½”ë“œ ìƒì„± |
| **GPT-3.5-Turbo** | ê°„ë‹¨í•œ ì‘ì—… | â­â­â­â­ | â­â­â­â­ | ìŒˆ | âœ… ìš”ì•½, ë¶„ë¥˜ |
| **text-embedding-3-small** | ì„ë² ë”© | â­â­â­â­ | â­â­â­â­â­ | ë§¤ìš°ìŒˆ | âœ… RAG |

#### **LLM ì„±ëŠ¥ ìµœì í™”**

```python
# 1. í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì „ë¬¸ ì›Œí¬í”Œë¡œìš° ì„¤ê³„ìì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ìì—°ì–´ ìš”ì²­ì„ ì‹¤í–‰ ê°€ëŠ¥í•œ JSON ì›Œí¬í”Œë¡œìš°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

ê·œì¹™:
1. ê° ë‹¨ê³„ëŠ” ëª…í™•í•œ ëª©í‘œë¥¼ ê°€ì ¸ì•¼ í•¨
2. ë°ì´í„° íë¦„ì€ ë‹¨ê³„ë³„ë¡œ ëª…í™•í•¨
3. ì˜¤ë¥˜ ì²˜ë¦¬ëŠ” í•„ìˆ˜
4. ë³€ìˆ˜ëª…ì€ snake_case ì‚¬ìš©

ì¶œë ¥ í˜•ì‹: ìœ íš¨í•œ JSON
"""

# 2. Few-shot í”„ë¡¬í”„íŒ…
examples = [
    {
        "input": "ë„¤ì´ë²„ ë‰´ìŠ¤ì—ì„œ IT ë‰´ìŠ¤ 3ê°œë¥¼ í¬ë¡¤ë§í•´ì¤˜",
        "output": {
            "workflow": {
                "name": "Naver IT News Crawler",
                "steps": [
                    {"type": "API_CALL", "service": "naver", ...},
                    {"type": "DATA_FILTER", "query": "IT", ...},
                    {"type": "DATA_FORMAT", "format": "json", ...}
                ]
            }
        }
    }
]

# 3. í† í° ìµœì í™”
async def optimize_prompt(query: str, max_tokens: int = 4096):
    """
    í† í° ì‚¬ìš©ëŸ‰ ìµœì í™”:
    - ë¶ˆí•„ìš”í•œ ì„¤ëª… ì œê±°
    - í•µì‹¬ ì •ë³´ë§Œ í¬í•¨
    - ì»¨í…ìŠ¤íŠ¸ ì°½ íš¨ìœ¨ì  ì‚¬ìš©
    """
    return compressed_prompt
```

---

## 2ï¸âƒ£ **LangGraph - ì—ì´ì „íŠ¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜**

### **LangGraphë€?**

```
LangGraphëŠ” Multi-step ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.

íŠ¹ì§•:
âœ… ìƒíƒœ ê´€ë¦¬ (State Machine)
âœ… ë„êµ¬ ì‚¬ìš© (Tool Use)
âœ… ì¡°ê±´ë¶€ ë¶„ê¸° (Conditional Branching)
âœ… ë£¨í•‘ (Agentic Loop)

ğŸ“Œ í˜„ì¬ ìƒíƒœ: âœ… **ì™„ì „íˆ ì ìš©ë¨** (v0.2.45)
```

### **í”„ë¡œì íŠ¸ì— ì´ë¯¸ ì ìš©ëœ êµ¬í˜„**

#### **1ï¸âƒ£ WorkflowState ì •ì˜** (`src/engines/workflow_state.py`)

```python
from typing import TypedDict, List, Dict, Any, Optional

class StepStatus(TypedDict):
    """ê° ìŠ¤í…ì˜ ìƒíƒœ"""
    status: str                    # PENDING, RUNNING, SUCCESS, FAILED
    output: Optional[Dict[str, Any]]
    error: Optional[str]
    started_at: Optional[datetime]
    completed_at: Optional[datetime]

class WorkflowState(TypedDict):
    """LangGraph ì›Œí¬í”Œë¡œìš° ìƒíƒœ"""
    workflow_id: str               # ì›Œí¬í”Œë¡œìš° ID
    execution_id: str              # ì‹¤í–‰ ID
    current_step_index: int        # í˜„ì¬ ìŠ¤í… ì¸ë±ìŠ¤
    variables: Dict[str, Any]      # ì›Œí¬í”Œë¡œìš° ë³€ìˆ˜ (ë°ì´í„° ì „ë‹¬ìš©)
    step_results: List[Dict]       # ê° ìŠ¤í… ê²°ê³¼ ëˆ„ì 
    step_statuses: Dict[str, StepStatus]  # ìŠ¤í…ë³„ ìƒíƒœ
    execution_status: str          # ì „ì²´ ì‹¤í–‰ ìƒíƒœ
    approval_required: bool        # ìŠ¹ì¸ ëŒ€ê¸° ì—¬ë¶€
    approval_data: Optional[Dict]  # ìŠ¹ì¸ í•„ìš” ë°ì´í„°
    error: Optional[str]           # ì˜¤ë¥˜ ë©”ì‹œì§€
    total_duration: float          # ì´ ì‹¤í–‰ ì‹œê°„
```

#### **2ï¸âƒ£ WorkflowEngine êµ¬í˜„** (`src/engines/workflow_engine.py`)

```python
class WorkflowEngine:
    """LangGraph ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ ì—”ì§„"""
    
    def __init__(self):
        self.step_executor = StepExecutor()
        self.memory = MemorySaver()  # ìƒíƒœ ì²´í¬í¬ì¸íŠ¸
    
    def create_graph(
        self,
        workflow_steps: List[WorkflowStep],
        on_step_complete: Optional[Callable] = None,
    ) -> StateGraph:
        """âœ¨ LangGraph StateGraph ìƒì„±"""
        
        # Step 1: ìŠ¤í…ë³„ ë…¸ë“œ ìƒì„±
        graph = StateGraph(WorkflowState)
        
        for i, step in enumerate(sorted_steps):
            node_name = f"step_{step.order}_{step.id}"
            
            # ê° ìŠ¤í…ì„ LangGraph ë…¸ë“œë¡œ ì¶”ê°€
            async def step_node(state: WorkflowState, step=step):
                # ìŠ¤í… ì‹¤í–‰
                result = await self.step_executor.execute(
                    step,
                    state["variables"]
                )
                
                # ìƒíƒœ ì—…ë°ì´íŠ¸
                state["step_results"].append(result)
                state["variables"].update(result.get("variables", {}))
                
                return state
            
            graph.add_node(node_name, step_node)
        
        # Step 2: ì¡°ê±´ë¶€ ë¼ìš°íŒ… ì¶”ê°€
        graph.add_conditional_edges(
            current_node,
            lambda state: self._should_continue(state),  # ë¼ìš°íŒ… í•¨ìˆ˜
            {
                "continue": next_node,      # ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ
                "stop": END,               # ì¢…ë£Œ
                "wait_approval": END,      # ìŠ¹ì¸ ëŒ€ê¸°
            }
        )
        
        # Step 3: ê·¸ë˜í”„ ì»´íŒŒì¼ (ì²´í¬í¬ì¸íŠ¸ ì €ì¥ í™œì„±í™”)
        return graph.compile(checkpointer=self.memory)
    
    async def execute_workflow(
        self,
        workflow: Workflow,
        execution_id: str,
        variables: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ğŸš€ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (LangGraph ainvoke)"""
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        initial_state = WorkflowState(
            workflow_id=workflow.id,
            execution_id=execution_id,
            current_step_index=0,
            variables=variables,
            step_results=[],
            step_statuses={},
            execution_status="RUNNING",
            approval_required=False,
            approval_data=None,
            error=None,
            total_duration=0.0
        )
        
        # LangGraph ì‹¤í–‰
        graph = self.create_graph(workflow.steps)
        
        # âœ¨ ainvoke: ë¹„ë™ê¸° ì‹¤í–‰ (ìƒíƒœ ì¶”ì )
        final_state = await graph.ainvoke(
            initial_state,
            config={"configurable": {"thread_id": execution_id}}
        )
        
        return {
            "execution_id": execution_id,
            "final_state": final_state,
            "variables": final_state["variables"],
            "results": final_state["step_results"],
            "status": final_state["execution_status"]
        }
```

### **LangGraphì˜ í•µì‹¬ ë™ì‘**

```
1ï¸âƒ£ StateGraph ìƒì„±
   â”œâ”€ WorkflowState íƒ€ì… ì •ì˜
   â”œâ”€ ìŠ¤í…ë³„ ë…¸ë“œ ì¶”ê°€ (add_node)
   â””â”€ ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€ (add_conditional_edges)

2ï¸âƒ£ ì¡°ê±´ë¶€ ë¼ìš°íŒ…
   â”œâ”€ _should_continue() í•¨ìˆ˜ë¡œ ë‹¤ìŒ ì•¡ì…˜ ê²°ì •
   â”œâ”€ "continue" â†’ ë‹¤ìŒ ìŠ¤í…
   â”œâ”€ "stop" â†’ ì›Œí¬í”Œë¡œìš° ì¢…ë£Œ
   â””â”€ "wait_approval" â†’ ìŠ¹ì¸ ëŒ€ê¸°

3ï¸âƒ£ ìƒíƒœ ê´€ë¦¬
   â”œâ”€ ê° ìŠ¤í… í›„ WorkflowState ì—…ë°ì´íŠ¸
   â”œâ”€ step_resultsì— ê²°ê³¼ ëˆ„ì 
   â”œâ”€ variablesì— ë°ì´í„° ì „ë‹¬
   â””â”€ MemorySaverë¡œ ì²´í¬í¬ì¸íŠ¸ ì €ì¥

4ï¸âƒ£ ë¹„ë™ê¸° ì‹¤í–‰
   â””â”€ graph.ainvoke()ë¡œ ë¹„ë™ê¸° ì‹¤í–‰
```

### **í˜„ì¬ ì ìš© ìƒí™©** âœ…

| í•­ëª© | ìƒíƒœ | íŒŒì¼ | ì„¤ëª… |
|------|------|------|------|
| **StateGraph** | âœ… | `workflow_engine.py` | ìŠ¤í… ê¸°ë°˜ ê·¸ë˜í”„ ìƒì„± |
| **ì¡°ê±´ë¶€ ë¼ìš°íŒ…** | âœ… | `workflow_engine.py` | continue/stop/approval |
| **ìƒíƒœ ì¶”ì ** | âœ… | `workflow_state.py` | WorkflowState ì •ì˜ |
| **ì²´í¬í¬ì¸íŠ¸** | âœ… | `workflow_engine.py` | MemorySaver í†µí•© |
| **ë¹„ë™ê¸° ì‹¤í–‰** | âœ… | `workflow_engine.py` | ainvoke ì‚¬ìš© |
| **ì˜¤ë¥˜ ì²˜ë¦¬** | âœ… | `step_executor.py` | ì˜ˆì™¸ ì²˜ë¦¬ ë° ìƒíƒœ ê¸°ë¡ |

### **LangGraph ì‚¬ìš© íë¦„**

```
ì‚¬ìš©ì ì¿¼ë¦¬
    â†“
ì›Œí¬í”Œë¡œìš° ìƒì„± (JSON)
    â†“
WorkflowState ì´ˆê¸°í™”
    â†“
StateGraph ìƒì„±
    â”œâ”€ ìŠ¤í…1 ë…¸ë“œ + ë¼ìš°íŒ…
    â”œâ”€ ìŠ¤í…2 ë…¸ë“œ + ë¼ìš°íŒ…
    â””â”€ ìŠ¤í…N ë…¸ë“œ + ì¢…ë£Œ
    â†“
graph.ainvoke() ì‹¤í–‰
    â”œâ”€ ìŠ¤í…1 ì‹¤í–‰ (ìƒíƒœ ì—…ë°ì´íŠ¸)
    â”œâ”€ ì¡°ê±´ë¶€ ë¼ìš°íŒ… (continue/stop)
    â”œâ”€ ìŠ¤í…2 ì‹¤í–‰ (ë³€ìˆ˜ ì „ë‹¬)
    â””â”€ ìµœì¢… ìƒíƒœ ë°˜í™˜
    â†“
ê²°ê³¼ ìˆ˜ì§‘ ë° ì €ì¥
```

### **LangGraphì˜ ì‹¤ì œ ì¥ì  (ì´ë¯¸ ëˆ„ë¦¬ê³  ìˆëŠ” ê²ƒ)**

```
âœ… ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ìë™ ê´€ë¦¬
   â†’ ìš°ë¦¬ëŠ” ìŠ¤í…ë§Œ ì •ì˜, LangGraphê°€ ì‹¤í–‰ íë¦„ ê´€ë¦¬

âœ… ìƒíƒœ ê¸°ë°˜ ë¡œì§
   â†’ ê° ìŠ¤í… í›„ ìë™ìœ¼ë¡œ ìƒíƒœ ì—…ë°ì´íŠ¸
   â†’ ë°ì´í„° ì†ì‹¤ ì—†ìŒ

âœ… ì¡°ê±´ë¶€ ë¶„ê¸° ì²˜ë¦¬
   â†’ if/else ë¡œì§ì„ ì„ ì–¸ì ìœ¼ë¡œ ì •ì˜
   â†’ ìœ ì§€ë³´ìˆ˜ ì‰¬ì›€

âœ… ë¹„ë™ê¸° ì‹¤í–‰ + ì²´í¬í¬ì¸íŠ¸
   â†’ ëŒ€ê·œëª¨ ì›Œí¬í”Œë¡œìš°ë„ ì•ˆì •ì  ì‹¤í–‰
   â†’ ì¤‘ë‹¨/ì¬ê°œ ê°€ëŠ¥

âœ… ë””ë²„ê¹… ìš©ì´
   â†’ LangGraphëŠ” ìƒíƒœ ë³€í™”ë¥¼ ê¸°ë¡
   â†’ ê° ìŠ¤í…ì˜ ì…ì¶œë ¥ ì¶”ì  ê°€ëŠ¥
```

---

## 3ï¸âƒ£ **RAG (Retrieval-Augmented Generation)**

### **í˜„ì¬ RAG ì•„í‚¤í…ì²˜**

```
ì‚¬ìš©ì ì¿¼ë¦¬ ì…ë ¥
    â†“
[Step 1] ì¿¼ë¦¬ ë¶„í•´ (Query Decomposition)
    â†“
[Step 2] ë„ë©”ì¸ë³„ ê²€ìƒ‰ (Domain-specific Search)
    â”œâ”€ collection_naver ê²€ìƒ‰
    â”œâ”€ collection_weather ê²€ìƒ‰
    â”œâ”€ collection_kakao ê²€ìƒ‰
    â”œâ”€ collection_google ê²€ìƒ‰
    â””â”€ collection_common ê²€ìƒ‰
    â†“
[Step 3] ê²°ê³¼ ìœµí•© (Result Fusion)
    â”œâ”€ ì¤‘ë³µ ì œê±°
    â”œâ”€ ìœ ì‚¬ë„ìˆœ ì •ë ¬
    â””â”€ ë„ë©”ì¸ ìš°ì„ ìˆœìœ„ ì ìš©
    â†“
[Step 4] ì „ì²´ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (Context Building)
    â†“
[Step 5] LLM í”„ë¡¬í”„íŠ¸ ìƒì„± (Prompt Generation)
    â†“
LLM ìƒì„± (ì›Œí¬í”Œë¡œìš° JSON)
```

### **RAG êµ¬í˜„ ìƒì„¸**

```python
class RAGService:
    def __init__(self):
        self.chroma_client = chromadb.PersistentClient()
        self.embedding_fn = OpenAIEmbeddingFunction()
    
    # ë„ë©”ì¸ë³„ ì»¬ë ‰ì…˜ ê´€ë¦¬
    DOMAINS = ["naver", "weather", "kakao", "google", "common"]
    
    async def search_with_domain_separation(
        self,
        query: str,
        target_domain: str = None,
        limit: int = 5
    ) -> List[Dict]:
        """
        ë„ë©”ì¸ë³„ ë¶„ë¦¬ ê²€ìƒ‰ ì „ëµ:
        
        1. target_domain ì§€ì • ì‹œ:
           - í•´ë‹¹ ë„ë©”ì¸ + common ê²€ìƒ‰ (ë„ë©”ì¸ ìš°ì„ )
        
        2. target_domain ë¯¸ì§€ì • ì‹œ:
           - ëª¨ë“  ë„ë©”ì¸ ê²€ìƒ‰ (ìœ ì‚¬ë„ìˆœ)
        """
        
        if target_domain:
            # íŠ¹ì • ë„ë©”ì¸ + common
            specific_collection = self._get_collection(target_domain)
            common_collection = self._get_collection("common")
            
            specific_results = await specific_collection.query(
                query_texts=[query],
                n_results=limit
            )
            common_results = await common_collection.query(
                query_texts=[query],
                n_results=limit
            )
            
            # ë³‘í•© (ë„ë©”ì¸ ìš°ì„ )
            results = self._merge_results(
                specific_results,
                common_results,
                primary_domain=target_domain
            )
        else:
            # ëª¨ë“  ë„ë©”ì¸ ê²€ìƒ‰
            all_results = []
            for domain in self.DOMAINS:
                collection = self._get_collection(domain)
                results = await collection.query(
                    query_texts=[query],
                    n_results=limit
                )
                all_results.extend(results)
            
            # ìœ ì‚¬ë„ìˆœ ì •ë ¬
            results = sorted(
                all_results,
                key=lambda x: x["similarity_score"],
                reverse=True
            )[:limit]
        
        return results
    
    async def build_context_for_workflow_generation(
        self,
        query: str,
        max_tokens: int = 30000
    ) -> str:
        """
        ì›Œí¬í”Œë¡œìš° ìƒì„±ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•
        """
        
        # 1. ì¿¼ë¦¬ ë¶„í•´
        subqueries = await self._decompose_query(query)
        
        # 2. ê° ì„œë¸Œì¿¼ë¦¬ë³„ ê²€ìƒ‰
        all_documents = []
        for subquery in subqueries:
            docs = await self.search_with_domain_separation(subquery)
            all_documents.extend(docs)
        
        # 3. ì¤‘ë³µ ì œê±°
        unique_docs = self._deduplicate(all_documents)
        
        # 4. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (í† í° ì œí•œ)
        context = self._build_context_within_token_limit(
            unique_docs,
            max_tokens
        )
        
        return context
```

### **RAGì˜ ì—­í• **

```
RAGë¥¼ í†µí•´ ì–»ëŠ” ê²ƒ:
âœ… ìµœì‹  ì •ë³´ (ë¬¸ì„œ ê¸°ë°˜)
âœ… ì •í™•í•œ ì •ë³´ (ì†ŒìŠ¤ ëª…ì‹œ)
âœ… í• ë£¨ì‹œë„¤ì´ì…˜ ê°ì†Œ
âœ… ë„ë©”ì¸ íŠ¹í™” ì§€ì‹

í”„ë¡œì íŠ¸ì—ì„œ:
â†’ ì›Œí¬í”Œë¡œìš° ìƒì„± ì‹œ í•„ìš”í•œ ëª¨ë“  ì •ë³´ ì œê³µ
â†’ ë„ë©”ì¸ë³„ íŠ¹í™” ë¬¸ì„œ ìš°ì„  ì œì‹œ
â†’ ê³µí†µ ê¸°ìˆ  ë¬¸ì„œëŠ” í•­ìƒ í¬í•¨
```

---

## 4ï¸âƒ£ **MCP (Model Context Protocol) - ì¶”í›„ ë„ì…**

### **MCPë€?**

```
MCPëŠ” LLMê³¼ ì™¸ë¶€ ë„êµ¬/ë°ì´í„°ì†ŒìŠ¤ë¥¼ ì—°ê²°í•˜ëŠ” í‘œì¤€ í”„ë¡œí† ì½œì…ë‹ˆë‹¤.

ì¥ì :
âœ… í‘œì¤€í™”ëœ ë„êµ¬ ì—°ë™
âœ… í”ŒëŸ¬ê·¸ì¸ ìƒíƒœê³„
âœ… ë³´ì•ˆ (ê¶Œí•œ ê´€ë¦¬)
âœ… í™•ì¥ì„± (ìƒˆë¡œìš´ ë„êµ¬ ì‰½ê²Œ ì¶”ê°€)
```

### **í”„ë¡œì íŠ¸ì—ì„œì˜ ë¯¸ë˜ í™œìš©**

```python
# MCPë¥¼ í†µí•´ ì—°ë™í•  ë„êµ¬ë“¤
MCP_TOOLS = {
    "naver": {
        "api_endpoint": "https://api.naver.com",
        "tools": ["search", "news", "blog"],
        "permissions": ["read"]
    },
    "weather": {
        "api_endpoint": "https://api.kma.go.kr",
        "tools": ["forecast", "data"],
        "permissions": ["read"]
    },
    "database": {
        "endpoint": "postgresql://...",
        "tools": ["query", "insert", "update"],
        "permissions": ["read", "write"]
    },
    "code_executor": {
        "endpoint": "http://localhost:9000",
        "tools": ["execute", "validate"],
        "permissions": ["execute"]
    }
}

# MCP í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„ (ì¶”í›„)
class MCPClient:
    async def call_tool(
        self,
        tool_name: str,
        args: dict
    ):
        """
        "search_naver_news" í˜¸ì¶œ ì‹œ:
        1. MCP ì„œë²„ì— ìš”ì²­
        2. ê¶Œí•œ í™•ì¸
        3. ë„êµ¬ ì‹¤í–‰
        4. ê²°ê³¼ ë°˜í™˜
        """
        pass
```

### **MCP ë„ì… ì‹œ ì´ì **

```
í˜„ì¬ (ì§ì ‘ API í˜¸ì¶œ):
â”œâ”€ ê° ì„œë¹„ìŠ¤ë³„ ë”°ë¡œ êµ¬í˜„
â”œâ”€ ë³´ì•ˆ ê´€ë¦¬ ë³µì¡
â””â”€ ìƒˆë¡œìš´ ì„œë¹„ìŠ¤ ì¶”ê°€ ì–´ë ¤ì›€

MCP ë„ì… í›„:
â”œâ”€ í‘œì¤€ í”„ë¡œí† ì½œë¡œ í†µì¼
â”œâ”€ ì¤‘ì•™ ê¶Œí•œ ê´€ë¦¬
â””â”€ í”ŒëŸ¬ê·¸ì¸ì²˜ëŸ¼ ì¶”ê°€ ê°€ëŠ¥
```

---

## 5ï¸âƒ£ **Memory / Meta Memory - ìƒíƒœ ê´€ë¦¬**

### **Memory êµ¬ì¡°**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Session Memory (ë‹¨ê¸°)         â”‚
â”‚  í˜„ì¬ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸                â”‚
â”‚  - í˜„ì¬ ì›Œí¬í”Œë¡œìš°                 â”‚
â”‚  - ì‚¬ìš©ì ì…ë ¥ ê¸°ë¡               â”‚
â”‚  - ìµœê·¼ ìƒì„± ê²°ê³¼                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Persistent Memory (ì¥ê¸°)       â”‚
â”‚  ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥              â”‚
â”‚  - ì‚¬ìš©ì í”„ë¡œí•„                  â”‚
â”‚  - ì›Œí¬í”Œë¡œìš° ì´ë ¥                â”‚
â”‚  - ì„ í˜¸ë„                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Meta Memory (ë©”íƒ€ ì •ë³´)        â”‚
â”‚  ì‹œìŠ¤í…œ ë©”íƒ€ë°ì´í„°                â”‚
â”‚  - ì‚¬ìš© íŒ¨í„´                      â”‚
â”‚  - ì„±ëŠ¥ ì§€í‘œ                      â”‚
â”‚  - í•™ìŠµ ë°ì´í„°                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **êµ¬í˜„ ì˜ˆì‹œ**

```python
class MemoryManager:
    def __init__(self):
        self.session_memory = {}  # ë‹¨ê¸° ë©”ëª¨ë¦¬
        self.db = PostgreSQL()    # ì¥ê¸° ë©”ëª¨ë¦¬
        self.meta_store = Redis() # ë©”íƒ€ ë©”ëª¨ë¦¬
    
    # 1. Session Memory (ë‹¨ê¸°)
    class SessionMemory:
        def __init__(self, session_id: str):
            self.session_id = session_id
            self.conversation = []
            self.current_workflow = None
            self.context = {}
        
        async def add_turn(self, user_input: str, ai_response: str):
            """ëŒ€í™” í„´ ì¶”ê°€"""
            self.conversation.append({
                "user": user_input,
                "ai": ai_response,
                "timestamp": datetime.now()
            })
        
        async def get_context(self, max_turns: int = 5):
            """ìµœê·¼ ì»¨í…ìŠ¤íŠ¸ ë°˜í™˜"""
            return self.conversation[-max_turns:]
    
    # 2. Persistent Memory (ì¥ê¸°)
    class PersistentMemory:
        async def save_workflow(self, user_id: str, workflow: dict):
            """ì›Œí¬í”Œë¡œìš° ì €ì¥"""
            await db.insert(
                "user_workflows",
                {
                    "user_id": user_id,
                    "workflow": workflow,
                    "created_at": datetime.now()
                }
            )
        
        async def get_user_preferences(self, user_id: str):
            """ì‚¬ìš©ì ì„ í˜¸ë„ ë°˜í™˜"""
            return await db.query(
                "SELECT preferences FROM users WHERE id = ?",
                [user_id]
            )
    
    # 3. Meta Memory (ë©”íƒ€)
    class MetaMemory:
        async def record_query_pattern(self, user_id: str, query: str):
            """ì¿¼ë¦¬ íŒ¨í„´ ê¸°ë¡"""
            # ì‚¬ìš© í†µê³„ ìˆ˜ì§‘
            await redis.incr(f"query_pattern:{user_id}:{query_type}")
        
        async def record_performance(self, workflow_id: str, metrics: dict):
            """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ê¸°ë¡"""
            await redis.set(
                f"performance:{workflow_id}",
                json.dumps(metrics),
                ex=86400  # 1ì¼ TTL
            )
        
        async def get_trending_workflows(self, limit: int = 10):
            """ì¸ê¸° ì›Œí¬í”Œë¡œìš° ë°˜í™˜"""
            return await redis.zrange(
                "trending_workflows",
                0,
                limit - 1,
                withscores=True
            )
```

### **Memory í™œìš© ì‚¬ë¡€**

```python
# ì‚¬ìš© ì‚¬ë¡€ 1: ì‚¬ìš©ì ë§ì¶¤í˜• ì¶”ì²œ
async def recommend_workflows(user_id: str):
    # Meta Memory: ì‚¬ìš©ì ì¿¼ë¦¬ íŒ¨í„´ ë¶„ì„
    patterns = await meta_memory.get_user_patterns(user_id)
    
    # Persistent Memory: ì‚¬ìš©ì ì„ í˜¸ë„
    preferences = await persistent_memory.get_user_preferences(user_id)
    
    # Session Memory: í˜„ì¬ ì»¨í…ìŠ¤íŠ¸
    recent_queries = await session_memory.get_context()
    
    # ì¶”ì²œ ìƒì„±
    recommendations = ai.recommend(
        patterns,
        preferences,
        recent_queries
    )
    return recommendations

# ì‚¬ìš© ì‚¬ë¡€ 2: ì˜¤ë¥˜ ì˜ˆë°© (íŒ¨í„´ í•™ìŠµ)
async def predict_user_intent(user_id: str, query: str):
    # Meta Memory: ê³¼ê±° ì‹¤íŒ¨ íŒ¨í„´ í•™ìŠµ
    failure_patterns = await meta_memory.get_failure_patterns(user_id)
    
    # ì‚¬ìš©ìì˜ ì¿¼ë¦¬ê°€ ì‹¤íŒ¨ íŒ¨í„´ê³¼ ìœ ì‚¬í•œì§€ ì²´í¬
    if query.matches_failure_pattern(failure_patterns):
        # ì‚¬ì „ì— ê²½ê³  ì œì‹œ
        return await suggest_alternatives(query)
    
    return await normal_processing(query)
```

---

## ğŸ”„ **í†µí•© í”Œë¡œìš°**

```
ì‚¬ìš©ì ì¿¼ë¦¬
    â†“
[Session Memory] ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
    â†“
[LLM] ì˜ë„ ì´í•´
    â†“
[RAG] ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    â†“
[LangGraph] ë©€í‹°-ìŠ¤í… ì—ì´ì „íŠ¸ ì‹¤í–‰
    â”œâ”€ Plan (ê³„íš ìˆ˜ë¦½)
    â”œâ”€ Generate (ìƒì„±)
    â”œâ”€ Validate (ê²€ì¦)
    â””â”€ Refine (ì •ì œ)
    â†“
[MCP] ì™¸ë¶€ ë„êµ¬ í˜¸ì¶œ (ì¶”í›„)
    â†“
[Persistent Memory] ê²°ê³¼ ì €ì¥
    â†“
[Meta Memory] ì„±ëŠ¥ ê¸°ë¡
    â†“
ìµœì¢… ì›Œí¬í”Œë¡œìš° ë°˜í™˜
```

---

## ğŸ“Š **ê¸°ìˆ  ì„±ìˆ™ë„ ë¡œë“œë§µ**

```
í˜„ì¬ (Phase 1) âœ…
â”œâ”€ âœ… LLM ê¸°ë³¸ í†µí•©
â”œâ”€ âœ… RAG ë„ë©”ì¸ ë¶„ë¦¬
â”œâ”€ âœ… Session Memory
â””â”€ âœ… LangGraph ì™„ì „ ì ìš© (NEW!)
   â”œâ”€ StateGraph êµ¬í˜„
   â”œâ”€ ì¡°ê±´ë¶€ ë¼ìš°íŒ…
   â”œâ”€ ìƒíƒœ ì¶”ì 
   â””â”€ MemorySaver ì²´í¬í¬ì¸íŠ¸

ê·¼ì‹œê°„ (3ê°œì›”, Phase 2) ğŸš€
â”œâ”€ âœ… ê³ ê¸‰ Memory ì‹œìŠ¤í…œ (ì§€ì† í•™ìŠµ)
â”œâ”€ âœ… ë‹¤ì¤‘ ëª¨ë¸ ì§€ì›
â”œâ”€ âœ… LangGraph ê³ ë„í™”
â”‚  â”œâ”€ ë³‘ë ¬ ìŠ¤í… ì‹¤í–‰
â”‚  â”œâ”€ ë™ì  ë¼ìš°íŒ…
â”‚  â””â”€ ìŠ¤í… ì¬ì‹œë„ ë¡œì§
â””â”€ â³ MCP í”„ë¡œí† íƒ€ì…

ì¤‘ê¸° (6ê°œì›”, Phase 3) ğŸ¯
â”œâ”€ âœ… MCP ë³¸ê²© ë„ì…
â”œâ”€ âœ… ë„êµ¬ ìƒíƒœê³„
â”œâ”€ âœ… LangGraph ì—ì´ì „íŠ¸ ë£¨í”„
â””â”€ â³ ìê°€í•™ìŠµ ì‹œìŠ¤í…œ

ì¥ê¸° (1ë…„, Phase 4) ğŸŒŸ
â”œâ”€ âœ… ì™„ì „ ìë™í™” ì—ì´ì „íŠ¸
â”œâ”€ âœ… ì§€ì†ì  í•™ìŠµ
â”œâ”€ âœ… ì˜ˆì¸¡ ê¸°ëŠ¥
â””â”€ âœ… ìê¸° ìµœì í™”
```

---

## ğŸ’¡ **ì„ íƒ ê¸°ì¤€**

### **ì™œ ì´ ê³ ê¸‰ ê¸°ìˆ ë“¤ì¸ê°€?**

```
LLM: 
âœ… ìì—°ì–´ ì´í•´ ë° ìƒì„±
âœ… ë©€í‹°-íƒœìŠ¤í¬ ê°€ëŠ¥

LangGraph:
âœ… ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ê´€ë¦¬
âœ… ì¡°ê±´ë¶€ ë¶„ê¸° ì²˜ë¦¬

RAG:
âœ… ì •í™•í•œ ì •ë³´ ì œê³µ
âœ… í• ë£¨ì‹œë„¤ì´ì…˜ ê°ì†Œ

MCP:
âœ… í‘œì¤€í™”ëœ ë„êµ¬ ì—°ë™
âœ… í”ŒëŸ¬ê·¸ì¸ ìƒíƒœê³„

Memory:
âœ… ì‚¬ìš©ì ë§ì¶¤í™”
âœ… ì„±ëŠ¥ ìµœì í™”
```

---

**ì´ ê³ ê¸‰ ê¸°ìˆ  ìŠ¤íƒìœ¼ë¡œ ì§„ì •í•œ AI-Native ì‹œìŠ¤í…œì„ êµ¬ì¶•í•©ë‹ˆë‹¤!** ğŸš€
