#!/usr/bin/env python3
"""
DB ì €ì¥ëœ ì²­í¬ vs ê²€ìƒ‰ ì²­í¬ ë¹„êµ ì§„ë‹¨
"""
import sys
import os

# ê²½ë¡œ ì„¤ì • ìˆ˜ì •
sys.path.insert(0, os.path.dirname(__file__))
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

import asyncio
from src.database.session import get_session
from src.database.models import Document, DocumentChunk, KnowledgeBase
from src.services.rag_service import get_rag_service

async def main():
    print("=" * 80)
    print("ğŸ” DB ì €ì¥ ì²­í¬ vs ê²€ìƒ‰ ì²­í¬ ë¹„êµ ì§„ë‹¨")
    print("=" * 80)
    
    try:
        # 1. DBì— ì €ì¥ëœ ì²­í¬ í™•ì¸
        print("\n1ï¸âƒ£ DBì— ì €ì¥ëœ ì²­í¬ ì •ë³´")
        print("-" * 80)
        
        with get_session() as session:
            docs = session.query(Document).all()
            print(f"ì´ ë¬¸ì„œ: {len(docs)}ê°œ\n")
            
            for doc in docs:
                print(f"ğŸ“„ ë¬¸ì„œ: {doc.title}")
                print(f"   ID: {doc.id}")
                print(f"   Knowledge Base: {doc.knowledge_base.name if doc.knowledge_base else 'N/A'}")
                
                chunks = session.query(DocumentChunk).filter(
                    DocumentChunk.document_id == doc.id
                ).all()
                
                print(f"   ì €ì¥ëœ ì²­í¬ ìˆ˜: {len(chunks)}ê°œ")
                
                for chunk in chunks:
                    content_preview = chunk.content[:100] if chunk.content else "EMPTY"
                    print(f"     - Chunk {chunk.chunk_index}: {len(chunk.content)} ê¸€ì, {chunk.token_count} í† í°")
                    print(f"       ë¯¸ë¦¬ë³´ê¸°: {content_preview}...")
                print()
        
        # 2. ChromaDB ê²€ìƒ‰ ê²°ê³¼ í™•ì¸
        print("\n2ï¸âƒ£ ChromaDB ê²€ìƒ‰ ê²°ê³¼")
        print("-" * 80)
        
        rag_service = get_rag_service()
        
        test_query = "ì›Œí¬í”Œë¡œìš°"
        print(f"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{test_query}'\n")
        
        # ì§ì ‘ hybrid_search í˜¸ì¶œ
        results = await rag_service.hybrid_search(
            query=test_query,
            limit=10,
            include_context=True,
            context_radius=1
        )
        
        print(f"ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ\n")
        
        for i, result in enumerate(results, 1):
            metadata = result.get("metadata", {})
            content = result.get("content", "")
            content_preview = content[:100] if content else "EMPTY"
            
            print(f"  [{i}] ë¬¸ì„œ: {metadata.get('title', 'N/A')}")
            print(f"      Doc ID: {metadata.get('document_id', 'N/A')}")
            print(f"      Chunk Index: {metadata.get('chunk_index', 'N/A')}")
            print(f"      Content Length: {len(content)} ê¸€ì")
            print(f"      Score: {result.get('final_score', 'N/A')}")
            print(f"      Context Chunks Count: {result.get('context_chunks_count', 'N/A')}")
            print(f"      Context Range: {result.get('context_range', 'N/A')}")
            print(f"      ë¯¸ë¦¬ë³´ê¸°: {content_preview}...")
            print()
        
        # 3. build_context ì¶œë ¥ í™•ì¸
        print("\n3ï¸âƒ£ build_context ì¶œë ¥")
        print("-" * 80)
        
        if results:
            context = rag_service.build_context(results, max_tokens=30000)
            context_lines = context.split('\n')
            print(f"ì´ ì¤„ ìˆ˜: {len(context_lines)}")
            print(f"ì´ ê¸€ì ìˆ˜: {len(context)} ê¸€ì\n")
            
            # ê° ì„¹ì…˜ ë¶„ì„
            chunk_count = context.count('**')
            print(f"í¬í•¨ëœ ì²­í¬ ì„¹ì…˜: {chunk_count // 2}ê°œ")
            
            print("\nì²˜ìŒ 500ê¸€ì:")
            print("-" * 80)
            print(context[:500])
            print("\në§ˆì§€ë§‰ 500ê¸€ì:")
            print("-" * 80)
            print(context[-500:])
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
