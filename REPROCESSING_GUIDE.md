# 문서 재임베딩 가이드

## 📋 개요

이 가이드는 기존 문서들을 **새로운 최적화 설정**으로 다시 임베딩하는 방법을 설명합니다.

### 🔄 재임베딩이 필요한 이유

```
이전 설정 (문제):
- chunk_size = 1000 토큰
- overlap = 200 토큰
- 결과: 청크 많음 + 문맥 손실 + Chunk 2까지만 표시

새로운 설정 (개선됨):
- chunk_size = 1500 토큰 (+50%)
- overlap = 300 토큰 (+50%)
- 결과: 청크 적음 + 완전한 문맥 + 모든 청크 표시
```

---

## 🚀 실행 방법

### Step 1: 터미널 열기

**Windows**:
- `Ctrl + ~` (VS Code에서) 또는
- PowerShell 또는 Command Prompt 직접 실행

**Mac/Linux**:
- 터미널 열기

### Step 2: 프로젝트 디렉토리로 이동

```bash
cd C:\dev\cursor\projWorkFlow4
# 또는
cd /path/to/projWorkFlow4
```

### Step 3: 재임베딩 스크립트 실행

```bash
python reprocess_documents.py
```

### Step 4: 진행 상황 모니터링

```
🔄 문서 재임베딩 시작
============================================================
⚠️  주의:
   - 모든 기존 청크가 삭제되고 새로 생성됩니다
   - ChromaDB가 재생성됩니다
   - 시간이 소요됩니다 (문서 수에 따라 5-30분)

🚀 진행 중...

🗑️  ChromaDB 정리 중: ./data/chroma_db
   ✅ 백업 생성: ./data/chroma_db.backup

🗑️  기존 청크 삭제 중...
   삭제할 청크: 125개
   ✅ 모든 청크 삭제됨

📚 문서 재임베딩 시작...
   설정: chunk_size=1500, overlap=300
============================================================

재임베딩할 문서: 15개

[1/15] 📄 문서 제목
   ID: doc_abc123
   ✅ 기존 청크 삭제됨
   ⏳ 재임베딩 중...
   ✅ 청크 생성: 3개 (이전보다 적을 것임)
   ✅ 임베딩 저장: 3개
   ✅ 완료!

[2/15] 📄 다른 문서
   ...

🎉 재임베딩 완료!
   성공: 15개
   실패: 0개

다음 단계:
   1. Streamlit 앱 재시작
   2. 워크플로우 생성 페이지에서 새 쿼리 시도
   3. RAG 컨텍스트가 더 많은 청크를 포함하는지 확인
```

---

## ⏱️ 예상 소요 시간

| 문서 수 | 평균 문서 크기 | 예상 시간 |
|--------|-------------|---------|
| 5-10개 | 5KB-20KB | 2-3분 |
| 10-20개 | 5KB-20KB | 5-10분 |
| 20-50개 | 5KB-20KB | 10-20분 |
| 50+개 | 5KB-20KB | 20-30분+ |

---

## ✅ 재임베딩 후 확인 사항

### 1️⃣ Streamlit 앱 재시작

```bash
# 기존 Streamlit 프로세스 중지
# (Ctrl+C)

# 다시 시작
streamlit run main.py
```

### 2️⃣ 워크플로우 생성 페이지 테스트

1. **새로운 워크플로우 생성**
   - 쿼리: "REST API를 호출하는 워크플로우"
   - 또는 "데이터 처리 파이프라인"

2. **RAG 컨텍스트 확인**
   - 🧠 또는 💭 아이콘 표시 확인
   - 컨텍스트 길이 확인

3. **생성된 워크플로우 검증**
   - 스텝이 충분한가?
   - 코드가 완전한가?

### 3️⃣ 로그 파일 확인

```bash
# 최신 로그 확인
cat ./logs/reprocess_documents_*.log

# 또는 (Windows)
type .\logs\reprocess_documents_*.log
```

---

## 🔍 문제 해결

### 문제: 스크립트가 멈춤

**해결책**:
1. Ctrl+C로 중단
2. 로그 파일 확인: `./logs/reprocess_documents_*.log`
3. 데이터베이스 연결 확인
4. `.env` 파일의 OPENAI_API_KEY 확인

### 문제: "DocumentChunk 테이블 잠금" 오류

**해결책**:
1. Streamlit 앱 완전히 종료
2. 다른 Python 프로세스 없는지 확인
3. 재시도

### 문제: 여전히 Chunk 2까지만 표시

**확인 사항**:
1. 재임베딩이 완전히 완료되었는가?
2. Streamlit 앱이 재시작되었는가?
3. 새로운 쿼리를 시도했는가?
4. 브라우저 캐시 초기화: Ctrl+F5

---

## 📊 전후 비교

### 이전 (최적화 전)

```
검색 쿼리: "Python 에러 처리"

result #1:
├─ Chunk 0: "Python 에러 처리의 중요성..."
│  ├─ 길이: 350 글자
│  └─ 포함됨: ✅

result #2:
├─ Chunk 1: "try-except 블록..."
│  ├─ 길이: 280 글자
│  └─ 포함됨: ❌ (제외됨 - doc_id 중복으로 간주)

결과: 불완전한 정보
```

### 이후 (최적화 후)

```
검색 쿼리: "Python 에러 처리"

result #1:
├─ Chunk 0: "Python 에러 처리의 중요성..."
│  ├─ 길이: 500 글자 (더 길어짐)
│  ├─ 문맥: 더 완전함
│  └─ 포함됨: ✅

result #2:
├─ Chunk 1: "try-except 블록..."
│  ├─ 길이: 450 글자 (더 길어짐)
│  ├─ 문맥: 더 완전함
│  └─ 포함됨: ✅

result #3:
├─ Chunk 2: "예외 처리 모범 사례..."
│  ├─ 길이: 480 글자
│  └─ 포함됨: ✅

결과: 완전한 정보 + 모든 청크 표시
```

---

## 🎯 재임베딩 완료 후 기대 효과

✅ **RAG 컨텍스트 개선**
- 더 많은 청크 포함
- 더 완전한 문맥 전달

✅ **워크플로우 생성 품질 향상**
- 더 정확한 코드 생성
- 더 적절한 스텝 구성

✅ **오류 해결 정확도 증가**
- 더 많은 관련 예제 포함
- 더 정확한 해결책 제시

---

## 📝 상세 스크립트 로직

### 1단계: ChromaDB 정리
```
./data/chroma_db/ → ./data/chroma_db.backup/ (백업)
기존 ChromaDB 삭제
```

### 2단계: 데이터베이스 청크 삭제
```
DocumentChunk 테이블에서 모든 레코드 삭제
(하지만 원본 문서는 유지)
```

### 3단계: 문서 재임베딩
```
for each document:
  1. 새로운 chunk_size(1500), overlap(300)으로 청크 생성
  2. 각 청크마다 OpenAI 임베딩 생성
  3. ChromaDB에 저장 (메타데이터 포함)
  4. DocumentChunk 레코드 생성
  5. 문서 메타데이터 업데이트
```

---

## 🚨 주의사항

1. **시간이 소요됩니다**
   - 중간에 중단하지 않기
   - 야간에 실행 권장

2. **API 비용 발생**
   - OpenAI 임베딩 API 호출
   - 문서 수에 따라 비용 차등

3. **데이터 백업**
   - `chroma_db.backup` 생성됨
   - 문제 발생 시 복구 가능

4. **Streamlit 앱 중지**
   - 재임베딩 중 앱 실행 금지
   - 데이터 충돌 방지

---

## 🎉 완료!

재임베딩이 완료되면:
1. Streamlit 앱 재시작
2. 새로운 워크플로우 생성 시도
3. RAG 컨텍스트의 개선 확인

더 이상 **"Chunk 2까지만 표시"** 문제가 발생하지 않을 것입니다! ✨
